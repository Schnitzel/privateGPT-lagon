FROM uselagoon/commons as commons
FROM wallies/python-cuda:3.10-cuda11.7-runtime

COPY --from=commons /lagoon /lagoon
COPY --from=commons /bin/fix-permissions /bin/ep /bin/docker-sleep /bin/wait-for /bin/
COPY --from=commons /sbin/tini /sbin/
COPY --from=commons /home /home

WORKDIR /privategpt

COPY ./src/requirements.txt src/requirements.txt
RUN pip install --upgrade pip \
    && ( /bin/bash -c "CMAKE_ARGS='-DLLAMA_OPENBLAS=on' FORCE_CMAKE=1 pip install \$(grep llama-cpp-python src/requirements.txt)" 2>&1 | tee llama-build.log ) \
    && ( pip install --no-cache-dir -r src/requirements.txt 2>&1 | tee pip-install.log ) \
    && pip cache purge

COPY ./src src

RUN fix-permissions /privategpt

CMD [ "sleep", "infinity" ]