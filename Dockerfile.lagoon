FROM wallies/python-cuda:3.10-cuda11.7-runtime

RUN groupadd -g 10009 -o privategpt && useradd -m -u 10009 -g 10009 -o -s /bin/bash privategpt
USER privategpt
WORKDIR /home/privategpt

COPY ./src/requirements.txt src/requirements.txt
RUN pip install --upgrade pip \
    && ( /bin/bash -c "CMAKE_ARGS='-DLLAMA_OPENBLAS=on' FORCE_CMAKE=1 pip install \$(grep llama-cpp-python src/requirements.txt)" 2>&1 | tee llama-build.log ) \
    && ( pip install --no-cache-dir -r src/requirements.txt 2>&1 | tee pip-install.log ) \
    && pip cache purge

COPY ./src src

CMD [ "sleep", "infinity" ]